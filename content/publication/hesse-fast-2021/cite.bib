@misc{hesse_fast_2021,
 abstract = {Mitigating the dependence on spurious correlations present in the training dataset is a quickly emerging and important topic of deep learning. Recent approaches include priors on the feature attribution of a deep neural network (DNN) into the training process to reduce the dependence on unwanted features. However, until now one needed to trade off high-quality attributions, satisfying desirable axioms, against the time required to compute them. This in turn either led to long training times or ineffective attribution priors. In this work, we break this trade-off by considering a special class of efﬁciently axiomatically attributable DNNs for which an axiomatic feature attribution can be computed with only a single forward/backward pass. We formally prove that nonnegatively homogeneous DNNs, here termed X -DNNs, are efﬁciently axiomatically attributable and show that they can be effortlessly constructed from a wide range of regular DNNs by simply removing the bias term of each layer. Various experiments demonstrate the advantages of X -DNNs, beating state-of-the-art generic attribution methods on regular DNNs for training with attribution priors.},
 annote = {Comment: To appear at NeurIPS*2021. Project page and code: https://visinf.github.io/fast-axiomatic-attribution},
 author = {Hesse, Robin and Schaub-Meyer, Simone and Roth, Stefan},
 file = {Hesse et al. - 2021 - Fast Axiomatic Attribution for Neural Networks.pdf:C\:\\Users\łexieli\\Zotero\\storage\\TCZIPWLU\e̋sse et al. - 2021 - Fast Axiomatic Attribution for Neural Networks.pdf:application/pdf},
 keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning},
 language = {en},
 month = {November},
 note = {arXiv:2111.07668 [cs]},
 publisher = {arXiv},
 title = {Fast Axiomatic Attribution for Neural Networks},
 url = {http://arxiv.org/abs/2111.07668},
 urldate = {2023-12-14},
 year = {2021}
}

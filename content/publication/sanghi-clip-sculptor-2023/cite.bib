@misc{sanghi_clip-sculptor_2023,
 abstract = {Recent works have demonstrated that natural language can be used to generate and edit 3D shapes. However, these methods generate shapes with limited fidelity and diversity. We introduce CLIP-Sculptor, a method to address these constraints by producing high-fidelity and diverse 3D shapes without the need for (text, shape) pairs during training. CLIP-Sculptor achieves this in a multi-resolution approach that first generates in a low-dimensional latent space and then upscales to a higher resolution for improved shape fidelity. For improved shape diversity, we use a discrete latent space which is modeled using a transformer conditioned on CLIP’s image-text embedding space. We also present a novel variant of classifier-free guidance, which improves the accuracy-diversity trade-off. Finally, we perform extensive experiments demonstrating that CLIP-Sculptor outperforms state-of-the-art baselines.},
 annote = {Comment: Accepted at Conference on Computer Vision and Pattern Recognition 2023(CVPR2023)},
 author = {Sanghi, Aditya and Fu, Rao and Liu, Vivian and Willis, Karl and Shayani, Hooman and Khasahmadi, Amir Hosein and Sridhar, Srinath and Ritchie, Daniel},
 file = {Sanghi et al. - 2023 - CLIP-Sculptor Zero-Shot Generation of High-Fideli.pdf:C\:\\Users\łexieli\\Zotero\\storage\\ZLBDJIHC\\Sanghi et al. - 2023 - CLIP-Sculptor Zero-Shot Generation of High-Fideli.pdf:application/pdf},
 keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Artificial Intelligence},
 language = {en},
 month = {May},
 note = {arXiv:2211.01427 [cs]},
 publisher = {arXiv},
 shorttitle = {CLIP-Sculptor},
 title = {CLIP-Sculptor: Zero-Shot Generation of High-Fidelity and Diverse Shapes from Natural Language},
 url = {http://arxiv.org/abs/2211.01427},
 urldate = {2023-12-14},
 year = {2023}
}

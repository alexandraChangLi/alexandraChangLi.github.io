---
title: '\"Why Should I Trust You?\": Explaining the Predictions of Any Classifier'
authors:
- Marco Tulio Ribeiro
- Sameer Singh
- Carlos Guestrin
date: '2016-08-01'
publishDate: '2024-01-15T06:08:03.521748Z'
publication_types:
- manuscript
publication: '*arXiv*'
abstract: 'Despite widespread adoption, machine learning models remain mostly black
  boxes. Understanding the reasons behind predictions is, however, quite important
  in assessing trust, which is fundamental if one plans to take action based on a
  prediction, or when choosing whether to deploy a new model. Such understanding also
  provides insights into the model, which can be used to transform an untrustworthy
  model or prediction into a trustworthy one. In this work, we propose LIME, a novel
  explanation technique that explains the predictions of any classiﬁer in an interpretable
  and faithful manner, by learning an interpretable model locally around the prediction.
  We also propose a method to explain models by presenting representative individual
  predictions and their explanations in a non-redundant way, framing the task as a
  submodular optimization problem. We demonstrate the ﬂexibility of these methods
  by explaining diﬀerent models for text (e.g. random forests) and image classiﬁcation
  (e.g. neural networks). We show the utility of explanations via novel experiments,
  both simulated and with human subjects, on various scenarios that require trust:
  deciding if one should trust a prediction, choosing between models, improving an
  untrustworthy classiﬁer, and identifying why a classiﬁer should not be trusted.'
tags:
- Computer Science - Machine Learning
- Computer Science - Artificial Intelligence
- Statistics - Machine Learning
links:
- name: URL
  url: http://arxiv.org/abs/1602.04938
---

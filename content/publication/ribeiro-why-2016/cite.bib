@misc{ribeiro_why_2016,
 abstract = {Despite widespread adoption, machine learning models remain mostly black boxes. Understanding the reasons behind predictions is, however, quite important in assessing trust, which is fundamental if one plans to take action based on a prediction, or when choosing whether to deploy a new model. Such understanding also provides insights into the model, which can be used to transform an untrustworthy model or prediction into a trustworthy one. In this work, we propose LIME, a novel explanation technique that explains the predictions of any classiﬁer in an interpretable and faithful manner, by learning an interpretable model locally around the prediction. We also propose a method to explain models by presenting representative individual predictions and their explanations in a non-redundant way, framing the task as a submodular optimization problem. We demonstrate the ﬂexibility of these methods by explaining diﬀerent models for text (e.g. random forests) and image classiﬁcation (e.g. neural networks). We show the utility of explanations via novel experiments, both simulated and with human subjects, on various scenarios that require trust: deciding if one should trust a prediction, choosing between models, improving an untrustworthy classiﬁer, and identifying why a classiﬁer should not be trusted.},
 annote = {This paper is gold. It proposes a local model approximation method and a submodular picking process for features to demonstrate what plays an important part in models’ decision making process. Greedy algorithm is used to solve to NP-optimization problem.
Various human-in-the-loop experiments demonstrates the effectiveness of this method. },
 author = {Ribeiro, Marco Tulio and Singh, Sameer and Guestrin, Carlos},
 file = {Ribeiro et al. - 2016 - Why Should I Trust You Explaining the Predicti.pdf:C\:\\Users\łexieli\\Zotero\\storage\\5AQHKANK\\Ribeiro et al. - 2016 - Why Should I Trust You Explaining the Predicti.pdf:application/pdf},
 keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence, Statistics - Machine Learning},
 language = {en},
 month = {August},
 note = {arXiv:1602.04938 [cs, stat]},
 publisher = {arXiv},
 shorttitle = {"Why Should I Trust You?},
 title = {"Why Should I Trust You?": Explaining the Predictions of Any Classifier},
 url = {http://arxiv.org/abs/1602.04938},
 urldate = {2023-12-14},
 year = {2016}
}

@misc{sundararajan_axiomatic_2017,
 abstract = {We study the problem of attributing the prediction of a deep network to its input features, a problem previously studied by several other works. We identify two fundamental axioms—Sensitivity and Implementation Invariance that attribution methods ought to satisfy. We show that they are not satisﬁed by most known attribution methods, which we consider to be a fundamental weakness of those methods. We use the axioms to guide the design of a new attribution method called Integrated Gradients. Our method requires no modiﬁcation to the original network and is extremely simple to implement; it just needs a few calls to the standard gradient operator. We apply this method to a couple of image models, a couple of text models and a chemistry model, demonstrating its ability to debug networks, to extract rules from a network, and to enable users to engage with models better.},
 annote = {This paper proposes two requirements that evaluation methods should satisfy and proposes that there are no methods that satisfy these two qualities. I doubt the second quality to be reasonable.
It argues that everything can be traced back into the gradient calculation method. Instead of the chain rule, this paper proposes to calculate gradients using integral calculation.
It is a very interesting approach while I doubt its relation with its proposals.
Also, it would be nice to demonstrate comparisons with other methods.},
 author = {Sundararajan, Mukund and Taly, Ankur and Yan, Qiqi},
 file = {Sundararajan et al. - 2017 - Axiomatic Attribution for Deep Networks.pdf:C\:\\Users\łexieli\\Zotero\\storage\F̋LR5ZLQ\\Sundararajan et al. - 2017 - Axiomatic Attribution for Deep Networks.pdf:application/pdf},
 keywords = {Computer Science - Machine Learning},
 language = {en},
 month = {June},
 note = {arXiv:1703.01365 [cs]},
 publisher = {arXiv},
 title = {Axiomatic Attribution for Deep Networks},
 url = {http://arxiv.org/abs/1703.01365},
 urldate = {2023-12-14},
 year = {2017}
}

@misc{ancona_towards_2018,
 abstract = {Understanding the ﬂow of information in Deep Neural Networks (DNNs) is a challenging problem that has gain increasing attention over the last few years. While several methods have been proposed to explain network predictions, there have been only a few attempts to compare them from a theoretical perspective. What is more, no exhaustive empirical comparison has been performed in the past. In this work, we analyze four gradient-based attribution methods and formally prove conditions of equivalence and approximation between them. By reformulating two of these methods, we construct a uniﬁed framework which enables a direct comparison, as well as an easier implementation. Finally, we propose a novel evaluation metric, called Sensitivity-n and test the gradient-based attribution methods alongside with a simple perturbation-based attribution method on several datasets in the domains of image and text classiﬁcation, using various network architectures.},
 annote = {Comment: ICLR 2018},
 author = {Ancona, Marco and Ceolini, Enea and Öztireli, Cengiz and Gross, Markus},
 file = {Ancona et al. - 2018 - Towards better understanding of gradient-based att.pdf:C\:\\Users\łexieli\\Zotero\\storage\\JRR2NSAY\\Ancona et al. - 2018 - Towards better understanding of gradient-based att.pdf:application/pdf},
 keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
 language = {en},
 month = {March},
 note = {arXiv:1711.06104 [cs, stat]},
 publisher = {arXiv},
 title = {Towards better understanding of gradient-based attribution methods for Deep Neural Networks},
 url = {http://arxiv.org/abs/1711.06104},
 urldate = {2023-12-14},
 year = {2018}
}

---
title: Fourier Features Let Networks Learn High Frequency Functions in Low Dimensional
  Domains
authors:
- Matthew Tancik
- Pratul P. Srinivasan
- Ben Mildenhall
- Sara Fridovich-Keil
- Nithin Raghavan
- Utkarsh Singhal
- Ravi Ramamoorthi
- Jonathan T. Barron
- Ren Ng
date: '2020-06-01'
publishDate: '2024-01-15T06:08:04.262212Z'
publication_types:
- manuscript
publication: '*arXiv*'
abstract: We show that passing input points through a simple Fourier feature mapping
  enables a multilayer perceptron (MLP) to learn high-frequency functions in lowdimensional
  problem domains. These results shed light on recent advances in computer vision
  and graphics that achieve state-of-the-art results by using MLPs to represent complex
  3D objects and scenes. Using tools from the neural tangent kernel (NTK) literature,
  we show that a standard MLP fails to learn high frequencies both in theory and in
  practice. To overcome this spectral bias, we use a Fourier feature mapping to transform
  the effective NTK into a stationary kernel with a tunable bandwidth. We suggest
  an approach for selecting problem-speciÔ¨Åc Fourier features that greatly improves
  the performance of MLPs for low-dimensional regression tasks relevant to the computer
  vision and graphics communities.
tags:
- Computer Science - Computer Vision and Pattern Recognition
- Computer Science - Machine Learning
links:
- name: URL
  url: http://arxiv.org/abs/2006.10739
---

@misc{wang_boosting_2022,
 abstract = {Central to active learning (AL) is what data should be selected for annotation. Existing works attempt to select highly uncertain or informative data for annotation. Nevertheless, it remains unclear how selected data impacts the test performance of the task model used in AL. In this work, we explore such an impact by theoretically proving that selecting unlabeled data of higher gradient norm leads to a lower upper-bound of test loss, resulting in a better test performance. However, due to the lack of label information, directly computing gradient norm for unlabeled data is infeasible. To address this challenge, we propose two schemes, namely expected-gradnorm and entropy-gradnorm. The former computes the gradient norm by constructing an expected empirical loss while the latter constructs an unsupervised loss with entropy. Furthermore, we integrate the two schemes in a universal AL framework. We evaluate our method on classical image classiﬁcation and semantic segmentation tasks. To demonstrate its competency in domain applications and its robustness to noise, we also validate our method on a cellular imaging analysis task, namely cryo-Electron Tomography subtomogram classiﬁcation. Results demonstrate that our method achieves superior performance against the state of the art. Our source code is available at https://github.com/xulabs/aitom/blob/master/doc/projects/ al gradnorm.md.},
 annote = {Comment: 13 pages},
 author = {Wang, Tianyang and Li, Xingjian and Yang, Pengkun and Hu, Guosheng and Zeng, Xiangrui and Huang, Siyu and Xu, Cheng-Zhong and Xu, Min},
 file = {Wang et al. - 2022 - Boosting Active Learning via Improving Test Perfor.pdf:C\:\\Users\łexieli\\Zotero\\storage\\48QXFYFI\\Wang et al. - 2022 - Boosting Active Learning via Improving Test Perfor.pdf:application/pdf},
 keywords = {Computer Science - Machine Learning},
 language = {en},
 month = {January},
 note = {arXiv:2112.05683 [cs]},
 publisher = {arXiv},
 title = {Boosting Active Learning via Improving Test Performance},
 url = {http://arxiv.org/abs/2112.05683},
 urldate = {2023-12-14},
 year = {2022}
}

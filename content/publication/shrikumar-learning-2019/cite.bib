@misc{shrikumar_learning_2019,
 abstract = {The purported “black box” nature of neural networks is a barrier to adoption in applications where interpretability is essential. Here we present DeepLIFT (Deep Learning Important FeaTures), a method for decomposing the output prediction of a neural network on a speciﬁc input by backpropagating the contributions of all neurons in the network to every feature of the input. DeepLIFT compares the activation of each neuron to its ‘reference activation’ and assigns contribution scores according to the difference. By optionally giving separate consideration to positive and negative contributions, DeepLIFT can also reveal dependencies which are missed by other approaches. Scores can be computed efﬁciently in a single backward pass. We apply DeepLIFT to models trained on MNIST and simulated genomic data, and show signiﬁcant advantages over gradient-based methods. Video tutorial: http://goo.gl/qKb7pL, ICML slides: bit.ly/deeplifticmlslides, ICML talk: https://vimeo.com/238275076, code: http://goo.gl/RM8jvH.},
 annote = {Comment: Updated to include changes present in the ICML camera-ready paper, and other small corrections},
 author = {Shrikumar, Avanti and Greenside, Peyton and Kundaje, Anshul},
 file = {Shrikumar et al. - 2019 - Learning Important Features Through Propagating Ac.pdf:C\:\\Users\łexieli\\Zotero\\storage\\TNS53LPG\\Shrikumar et al. - 2019 - Learning Important Features Through Propagating Ac.pdf:application/pdf},
 keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning, Computer Science - Neural and Evolutionary Computing},
 language = {en},
 month = {October},
 note = {arXiv:1704.02685 [cs]},
 publisher = {arXiv},
 title = {Learning Important Features Through Propagating Activation Differences},
 url = {http://arxiv.org/abs/1704.02685},
 urldate = {2023-12-14},
 year = {2019}
}

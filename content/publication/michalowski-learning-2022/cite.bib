@incollection{michalowski_learning_2022,
 abstract = {Clinical event sequences in Electronic Health Records (EHRs) record detailed information about the patient condition and patient care as they occur in time. Recent years have witnessed increased interest of machine learning community in developing machine learning models solving diﬀerent types of problems deﬁned upon information in EHRs. More recently, neural sequential models, such as RNN and LSTM, became popular and widely applied models for representing patient sequence data and for predicting future events or outcomes based on such data. However, a single neural sequential model may not properly represent complex dynamics of all patients and the diﬀerences in their behaviors. In this work, we aim to alleviate this limitation by reﬁning a one-ﬁts-all model using a Mixture-of-Experts (MoE) architecture. The architecture consists of multiple (expert) RNN models covering patient sub-populations and reﬁning the predictions of the base model. That is, instead of training expert RNN models from scratch we deﬁne them on the residual signal that attempts to model the diﬀerences from the population-wide model. The heterogeneity of various patient sequences is modeled through multiple experts that consist of RNN. Particularly, instead of directly training MoE from scratch, we augment MoE based on the prediction signal from pretrained base GRU model. With this way, the mixture of experts can provide ﬂexible adaptation to the (limited) predictive power of the single base RNN model. We experiment with the newly proposed model on realworld EHRs data and the multivariate clinical event prediction task. We implement RNN using Gated Recurrent Units (GRU). We show 4.1% gain on AUPRC statistics compared to a single RNN prediction.},
 address = {Cham},
 author = {Lee, Jeong Min and Hauskrecht, Milos},
 booktitle = {Artificial Intelligence in Medicine},
 doi = {10.1007/978-3-031-09342-5_15},
 editor = {Michalowski, Martin and Abidi, Syed Sibte Raza and Abidi, Samina},
 file = {Lee and Hauskrecht - 2022 - Learning to Adapt Dynamic Clinical Event Sequences.pdf:C\:\\Users\łexieli\\Zotero\\storage\\MQ3YRGAW\Łee and Hauskrecht - 2022 - Learning to Adapt Dynamic Clinical Event Sequences.pdf:application/pdf},
 isbn = {978-3-031-09341-8 978-3-031-09342-5},
 language = {en},
 note = {Series Title: Lecture Notes in Computer Science},
 pages = {155--166},
 publisher = {Springer International Publishing},
 title = {Learning to Adapt Dynamic Clinical Event Sequences with Residual Mixture of Experts},
 url = {https://link.springer.com/10.1007/978-3-031-09342-5_15},
 urldate = {2023-12-14},
 volume = {13263},
 year = {2022}
}

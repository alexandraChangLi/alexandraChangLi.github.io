@article{ying_gnnexplainer_nodate,
 abstract = {Graph Neural Networks (GNNs) are a powerful tool for machine learning on graphs. GNNs combine node feature information with the graph structure by recursively passing neural messages along edges of the input graph. However, incorporating both graph structure and feature information leads to complex models and explaining predictions made by GNNs remains unsolved. Here we propose GNNEXPLAINER, the ﬁrst general, model-agnostic approach for providing interpretable explanations for predictions of any GNN-based model on any graph-based machine learning task. Given an instance, GNNEXPLAINER identiﬁes a compact subgraph structure and a small subset of node features that have a crucial role in GNN’s prediction. Further, GNNEXPLAINER can generate consistent and concise explanations for an entire class of instances. We formulate GNNEXPLAINER as an optimization task that maximizes the mutual information between a GNN’s prediction and distribution of possible subgraph structures. Experiments on synthetic and real-world graphs show that our approach can identify important graph structures as well as node features, and outperforms alternative baseline approaches by up to 43.0% in explanation accuracy. GNNEXPLAINER provides a variety of beneﬁts, from the ability to visualize semantically relevant structures to interpretability, to giving insights into errors of faulty GNNs.},
 annote = {This paper utilizes masks to select sub-graphs for explaining GNN classifier’s outcome. Instead of explaining, I would like to describe it as: ‘identifying critical patterns’ that resembles certain classes.
It is done through minimizing a certain loss, aiming at training a mask, M (I think M is the goal of the training but did not look for specific proofs).
I think this is interesting. But I cannot see the potential in applying it to quant tasks, since the demonstrations provided in the experiments sections are largely chemical molecules that diverse in graph nodes and paths among nodes. However, among quant features, I do not think that they have various innate connections.},
 author = {Ying, Zhitao and Bourgeois, Dylan and You, Jiaxuan and Zitnik, Marinka and Leskovec, Jure},
 file = {Ying et al. - GNNExplainer Generating Explanations for Graph Ne.pdf:C\:\\Users\łexieli\\Zotero\\storage\\UL2LV9DP\\Ying et al. - GNNExplainer Generating Explanations for Graph Ne.pdf:application/pdf},
 language = {en},
 title = {GNNExplainer: Generating Explanations for Graph Neural Networks}
}

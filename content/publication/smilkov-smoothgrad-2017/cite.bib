@misc{smilkov_smoothgrad_2017,
 abstract = {Explaining the output of a deep network remains a challenge. In the case of an image classiﬁer, one type of explanation is to identify pixels that strongly inﬂuence the ﬁnal decision. A starting point for this strategy is the gradient of the class score function with respect to the input image. This gradient can be interpreted as a sensitivity map, and there are several techniques that elaborate on this basic idea. This paper makes two contributions: it introduces SMOOTHGRAD, a simple method that can help visually sharpen gradient-based sensitivity maps, and it discusses lessons in the visualization of these maps. We publish the code for our experiments and a website with our results.},
 annote = {Comment: 10 pages},
 author = {Smilkov, Daniel and Thorat, Nikhil and Kim, Been and Viégas, Fernanda and Wattenberg, Martin},
 file = {Smilkov et al. - 2017 - SmoothGrad removing noise by adding noise.pdf:C\:\\Users\łexieli\\Zotero\\storage\Ł5HMSKFL\\Smilkov et al. - 2017 - SmoothGrad removing noise by adding noise.pdf:application/pdf},
 keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning, Statistics - Machine Learning},
 language = {en},
 month = {June},
 note = {arXiv:1706.03825 [cs, stat]},
 publisher = {arXiv},
 shorttitle = {SmoothGrad},
 title = {SmoothGrad: removing noise by adding noise},
 url = {http://arxiv.org/abs/1706.03825},
 urldate = {2023-12-14},
 year = {2017}
}
